{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secret sharing reference communication benchmark\n",
    "In this notebook we try to count the amount of communication that is needed between workers and the executor to get an idea for how much communication is a bottleneck. In this reference example, every computational step is coordinated by the notebook which acts as a virtual central sever, in the real world this is different. \n",
    "\n",
    "## Conclusion\n",
    "This is an artifical example in that all communication goes through 'me' and there is no communication between the workers. We counted **26 messages** were received. But this number does not reflect the real case in 2 ways:\n",
    "* No message is sent/received when data moves from the worker to the central orchestrator, this will happen in the real case.\n",
    "* All communication is with the central orchestrator and not worker-to-worker.\n",
    "\n",
    "We got the feeling that the virtualworkers mimic the API 1-to-1, but the communication doesn't actually match with real workers. See also: https://github.com/OpenMined/PySyft/issues/5218\n",
    "\n",
    "So: to get a better picture we would need to investigate this in a more realistic setup with actual workers instead of virtual ones running in the same python instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "import torch as th\n",
    "\n",
    "hook = sy.TorchHook(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingWorker(sy.VirtualWorker):\n",
    "    \"\"\"\n",
    "    A virtual worker that logs sent and received messages.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.send_history = list()\n",
    "        self.recv_history = list()\n",
    "        \n",
    "    def send_msg(self, message, location: \"BaseWorker\") -> object:\n",
    "        \"\"\"Implements the logic to send messages.\n",
    "        The message is serialized and sent to the specified location. The\n",
    "        response from the location (remote worker) is deserialized and\n",
    "        returned back.\n",
    "        Every message uses this method.\n",
    "        Args:\n",
    "            msg_type: A integer representing the message type.\n",
    "            message: A Message object\n",
    "            location: A BaseWorker instance that lets you provide the\n",
    "                destination to send the message.\n",
    "        Returns:\n",
    "            The deserialized form of message from the worker at specified\n",
    "            location.\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(f\"worker {self} sending {message} to {location}\")\n",
    "            \n",
    "        # Step 1: serialize the message to a binary\n",
    "        bin_message = sy.serde.serialize(message, worker=self)\n",
    "\n",
    "        # Step 2: send the message and wait for a response\n",
    "        bin_response = self._send_msg(bin_message, location)\n",
    "\n",
    "        # Step 3: deserialize the response\n",
    "        response = sy.serde.deserialize(bin_response, worker=self)\n",
    "        \n",
    "        self.send_history.append((message, len(bin_message)))\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def recv_msg(self, bin_message: bin) -> bin:\n",
    "        \"\"\"Implements the logic to receive messages.\n",
    "        The binary message is deserialized and routed to the appropriate\n",
    "        function. And, the response serialized the returned back.\n",
    "        Every message uses this method.\n",
    "        Args:\n",
    "            bin_message: A binary serialized message.\n",
    "        Returns:\n",
    "            A binary message response.\n",
    "        \"\"\"\n",
    "        # Step 0: deserialize message\n",
    "        msg = sy.serde.deserialize(bin_message, worker=self)\n",
    "\n",
    "        # Step 1: save message and/or log it out\n",
    "        if self.log_msgs:\n",
    "            self.msg_history.append(msg)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f\"worker {self} received {type(msg).__name__} {msg.contents}\"\n",
    "                if hasattr(msg, \"contents\")\n",
    "                else f\"worker {self} received {type(msg).__name__}\"\n",
    "            )\n",
    "        self.recv_history.append((msg, len(bin_message)))\n",
    "\n",
    "        # Step 2: route message to appropriate function\n",
    "\n",
    "        response = None\n",
    "        for handler in self.message_handlers:\n",
    "            if handler.supports(msg):\n",
    "                response = handler.handle(msg)\n",
    "                break\n",
    "        # TODO(karlhigley): Raise an exception if no handler is found\n",
    "\n",
    "        # Step 3: Serialize the message to simple python objects\n",
    "        bin_response = sy.serde.serialize(response, worker=self)\n",
    "\n",
    "        return bin_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step one: defining the parties\n",
    "\n",
    "Alice and bob will be the data owners.\n",
    "There is an implicit third party called \"me\" which is the party which runs the code, holds the pointers to the data, and will also be the crypto provider because we haven't defined a separate crypto provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Worker bob already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "Worker alice already exists. Replacing old worker which could cause                     unexpected behavior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<LoggingWorker id:bob #objects:0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice = LoggingWorker(hook, id='alice')\n",
    "bob = LoggingWorker(hook, id='bob')\n",
    "\n",
    "alice.add_workers([bob])\n",
    "bob.add_workers([alice])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step two: storing the data\n",
    "Two tensors _x_ and _y_ are defined and sent to Alice and Bob. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{30156683280: tensor([1., 2., 3.])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = th.Tensor([1,2,3])\n",
    "y = th.Tensor([4,5,6])\n",
    "\n",
    "x_p = x.send(alice)\n",
    "y_p = y.send(bob)\n",
    "\n",
    "alice._objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step three: sharing secrets\n",
    "`x` and `y` are converted to fixed precision values and encrypted into shared secrets.\n",
    "Alice and Bob now contain an AdditiveSharingTensor, which contains pointers to all the secret shares at the different locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{30156683280: tensor([1., 2., 3.]),\n",
       " 49108460429: tensor([-7861231453757190850,   162443217343479452,  1234102003147360136]),\n",
       " 92109403716: (Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
       " \t-> [PointerTensor | me:61923783235 -> bob:55329268038]\n",
       " \t-> [PointerTensor | me:62375302071 -> alice:49108460429]\n",
       " \t*crypto provider: me*,\n",
       " 71359208984: tensor([ 6255037113097608685,   -88234053770322261, -5700560230518340298])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_share = x_p.fix_prec().share(bob, alice)\n",
    "y_share = y_p.fix_prec().share(bob, alice)\n",
    "\n",
    "alice._objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step four: collecting the pointers for the shared secrets and performing the analysis\n",
    "In order to perform computations on the AdditiveSharingTensors they need to be moved to the same party by calling `get`. Mind you, this does not move the secret values, merely the pointers to the cryptographical pieces that are located at the different parties.\n",
    "\n",
    "After moving the tensors we can perform the analysis. The result of the analysis will be another AdditiveSharingTensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
       "\t-> [PointerTensor | me:97430375456 -> bob:17900866039]\n",
       "\t-> [PointerTensor | me:34459115429 -> alice:22120326466]\n",
       "\t*crypto provider: me*"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secret_result = (x_share.get() + y_share.get())/2\n",
    "secret_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step five: Getting the result of the computation\n",
    "After performing the computation it is time to decrypt the result and convert it back into a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5000, 3.5000, 4.5000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = secret_result.get().float_prec()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communication counting\n",
    "We count the number of received messages, as in this virtual example this is the only communication there seems to be. Everything seems to go through 'me', the workers do not send anything to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communication happened 26 times\n",
      "Average message size: 150.5 bytes\n"
     ]
    }
   ],
   "source": [
    "num_messages = len(bob.recv_history) + len(alice.recv_history)\n",
    "print(f'Communication happened {num_messages} times')\n",
    "average_size = (sum(size for msg, size in bob.recv_history) \n",
    "                + sum(size for msg, size in alice.recv_history)) / num_messages\n",
    "print(f'Average message size: {average_size} bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((ObjectMessage tensor([1., 2., 3.])), 385),\n",
       " ((TensorCommandMessage ComputationAction[3776333929 = tensor([1., 2., 3.]).fix_prec(owner=<VirtualWorker id:me #objects:0>)]),\n",
       "  116),\n",
       " ((TensorCommandMessage ComputationAction[92109403716 = (Wrapper)>FixedPrecisionTensor>tensor([1000, 2000, 3000]).share(<LoggingWorker id:bob #objects:1>, <LoggingWorker id:alice #objects:1>, protocol=snn, field=None, dtype=None, crypto_provider=None, requires_grad=False)]),\n",
       "  187),\n",
       " ((ObjectMessage tensor([-7861231453757190850,   162443217343479452,  1234102003147360136])),\n",
       "  398),\n",
       " ((ForceObjectDeleteMessage [3776333929]), 34),\n",
       " ((ObjectMessage tensor([ 6255037113097608685,   -88234053770322261, -5700560230518340298])),\n",
       "  398),\n",
       " ((ObjectRequestMessage (92109403716, None, '')), 42),\n",
       " ((TensorCommandMessage ComputationAction[65375042530 = tensor([-7861231453757190850,   162443217343479452,  1234102003147360136]).__add__(tensor([ 6255037113097608685,   -88234053770322261, -5700560230518340298]))]),\n",
       "  133),\n",
       " ((ForceObjectDeleteMessage [49108460429]), 38),\n",
       " ((ForceObjectDeleteMessage [71359208984]), 38),\n",
       " ((TensorCommandMessage ComputationAction[22120326466 = tensor([-1606194340659582165,    74209163573157191, -4466458227370980162]).__truediv__(2)]),\n",
       "  104),\n",
       " ((ForceObjectDeleteMessage [65375042530]), 38),\n",
       " ((ObjectRequestMessage (22120326466, None, '')), 42)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice.recv_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alice' send history is empty, this is strange because how did we get the result with her sending the result back to 'me'? And how did Alice secretly share her tensor with Bob? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice.send_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only if we move a tensor from alice to bob we see this in the logs, so inter-worker communication is logged, but the communication from a worker to 'me' is **not** logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:68732150258 -> bob:90086845621]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_p = result.send(alice)\n",
    "result_p.move(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((ObjectMessage tensor([2.5000, 3.5000, 4.5000])), 385)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice.send_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
